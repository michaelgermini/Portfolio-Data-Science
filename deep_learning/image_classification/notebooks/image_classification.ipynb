{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification (Transfer Learning)\n",
        "\n",
        "This notebook mirrors the Streamlit page implementation. It loads images from `../data/` (subfolders per class), builds a pretrained CNN (ResNet18/EfficientNet-B0), fine-tunes with optional backbone freezing, and reports accuracy, confusion matrix and per-class F1.\n",
        "\n",
        "Run in project root:\n",
        "\n",
        "```bash\n",
        ".venv\\Scripts\\activate\n",
        "jupyter lab deep_learning/image_classification/notebooks/image_classification.ipynb\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, efficientnet_b0\n",
        "from torchvision.models import ResNet18_Weights, EfficientNet_B0_Weights\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "DATA_ROOT = Path(__file__).resolve().parents[1] / 'data'\n",
        "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 2\n",
        "LR = 1e-3\n",
        "FREEZE_BACKBONE = True\n",
        "MODEL_NAME = 'ResNet18'  # or 'EfficientNet-B0'\n",
        "\n",
        "# Transforms\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "full_ds = datasets.ImageFolder(str(DATA_ROOT), transform=train_tf)\n",
        "classes = full_ds.classes\n",
        "n_total = len(full_ds)\n",
        "val_split = 0.2\n",
        "n_val = max(1, int(n_total * val_split))\n",
        "train_ds, val_ds = random_split(full_ds, [n_total - n_val, n_val])\n",
        "val_ds.dataset.transform = val_tf\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if MODEL_NAME == 'ResNet18':\n",
        "    weights = ResNet18_Weights.DEFAULT\n",
        "    model = resnet18(weights=weights)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, len(classes))\n",
        "else:\n",
        "    weights = EfficientNet_B0_Weights.DEFAULT\n",
        "    model = efficientnet_b0(weights=weights)\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, len(classes))\n",
        "\n",
        "if FREEZE_BACKBONE:\n",
        "    for name, p in model.named_parameters():\n",
        "        if (MODEL_NAME == 'ResNet18' and not name.startswith('fc')) or (MODEL_NAME != 'ResNet18' and not name.startswith('classifier.1')):\n",
        "            p.requires_grad = False\n",
        "\n",
        "model = model.to(device)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "# Train\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = crit(out, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "# Validate\n",
        "model.eval()\n",
        "true, pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        pr = torch.argmax(logits, dim=1)\n",
        "        true.extend(yb.cpu().numpy())\n",
        "        pred.extend(pr.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(true, pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(true, pred, average=None, labels=list(range(len(classes))), zero_division=0)\n",
        "cm = confusion_matrix(true, pred, labels=list(range(len(classes))))\n",
        "\n",
        "print('Accuracy:', acc)\n",
        "print('Per-class F1:', f1)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
